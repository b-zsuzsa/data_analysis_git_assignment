{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNjfsScCJ4Ia"
      },
      "source": [
        "# **Web Scraping Assignment - Data Analysis Course**\n",
        "\n",
        "**Welcome** to the Web Scraping assignment. Your task is to scrape rental price data for apartments in Cluj-Napoca from the OLX website and create meaningful visual representations of the collected data. Use Python and relevant libraries to extract, process, and visualize the information.\n",
        "\n",
        "---\n",
        "\n",
        "### **Task Description**\n",
        "\n",
        "The goal of this assignment is to scrape rental listings from OLX for apartments in Cluj-Napoca and analyze the relationship between apartment sizes, room categories, and rental prices. You will:\n",
        "\n",
        "1. **Extract Data** from multiple pages of OLX rental listings in Cluj-Napoca. [Visit the website here](https://www.olx.ro/imobiliare/apartamente-garsoniere-de-inchiriat/cluj-napoca/).\n",
        "2. **Visualize rental prices** as a function of apartment size.\n",
        "3. **Categorize apartments by the number of rooms** and analyze price variations across these categories.\n",
        "4. **Calculate average rental prices** for different size groups and room categories.\n",
        "\n",
        "---\n",
        "\n",
        "### **Data Collection & Web Scraping**\n",
        "\n",
        "- Use **BeautifulSoup** and **Requests** to extract rental prices, apartment sizes, and room numbers from OLX listings.\n",
        "- Scrape data from **multiple pages** to ensure a representative sample size.\n",
        "- Organize the data into a structured format such as a **Pandas DataFrame** for easier analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### **Data Visualization Requirements**\n",
        "\n",
        "- Create **various visualizations** to effectively represent the data and highlight trends.\n",
        "- Ensure the visualizations are easy to understand, with proper labels, titles, and legends.\n",
        "- Focus on visualizing the relationship between rental prices, apartment sizes, and room categories.\n",
        "\n",
        "---\n",
        "\n",
        "### **Submission Instructions**\n",
        "\n",
        "1. **Upload your solution to GitHub** in the same project as your previous assignment. If the dataset is too large to upload, provide a link to the data in your notebook.\n",
        "2. Ensure that the code is well-documented and easy to follow.\n",
        "\n",
        "---\n",
        "\n",
        "### **Exploration and Tools**\n",
        "\n",
        "For this assignment, you are encouraged to explore the following libraries:\n",
        "\n",
        "- **Requests**\n",
        "- **BeautifulSoup**\n",
        "\n",
        "To get started with web scraping, check out these tutorials that provide step-by-step guidance:\n",
        "\n",
        "- [Web Scraping Tutorial 1](https://colab.research.google.com/github/Giffy/AI_Intro-to-Machine-Learning/blob/master/Session-9/Intro_to_web_scraping.ipynb#scrollTo=nekvLjaS6WNz)  \n",
        "- [Web Scraping Tutorial 2](https://colab.research.google.com/github/nestauk/im-tutorials/blob/3-ysi-tutorial/notebooks/Web-Scraping/Web%20Scraping%20Tutorial.ipynb#scrollTo=qK-EQGZ6DAuv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PSP7IhZQDIJ"
      },
      "source": [
        "**Minimalist Example**\n",
        "\n",
        "Extracting all external links from the Wikipedia page about the blue whale:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tr_YUJEqJwXt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install requests_html\n",
        "!pip install lxml_html_clean\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ZTZfXuCQGcI"
      },
      "outputs": [],
      "source": [
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMAgF-BFQIIe"
      },
      "outputs": [],
      "source": [
        "def get_page (website_url):\n",
        "    session = HTMLSession()\n",
        "    session.headers['user-agent'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'\n",
        "    response = session.get(website_url, headers=session.headers)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wptIt9q6QMnk"
      },
      "outputs": [],
      "source": [
        "wiki_url = 'https://en.wikipedia.org/wiki/Blue_whale'\n",
        "blue_whale_page = get_page(wiki_url)\n",
        "soup = BeautifulSoup(blue_whale_page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8bN-lqp-QThL"
      },
      "outputs": [],
      "source": [
        "links = soup.find_all('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZjpTkt8rSef3"
      },
      "outputs": [],
      "source": [
        "external_links = [link['href'] for link in links if 'href' in link.attrs and \"https\" in link['href']]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
